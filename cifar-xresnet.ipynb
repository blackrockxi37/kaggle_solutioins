{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch.nn as nn\nimport numpy as np\nimport torch\nfrom torchvision.datasets import CIFAR10\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\nfrom torch.optim.lr_scheduler import StepLR\nfrom tqdm import tqdm\nfrom time import perf_counter\nfrom IPython.display import clear_output, display\n\nos.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(f'Device selected: {torch.cuda.get_device_name()}')\n\nimport timm","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-30T14:30:52.781666Z","iopub.execute_input":"2024-08-30T14:30:52.782497Z","iopub.status.idle":"2024-08-30T14:30:58.837175Z","shell.execute_reply.started":"2024-08-30T14:30:52.782442Z","shell.execute_reply":"2024-08-30T14:30:58.836374Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Device selected: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"class delay(): # класс для подсчёта времени выполнения\n    def __init__(self): \n        self.start = perf_counter()\n    def start(self):\n        self.start = perf_counter()\n        return self\n    def stop(self):\n        self.end = perf_counter() - self.start; \n        mins = int(self.end // 60)\n        secs = int(self.end % 60)\n        print(f'Time taken:\\t{mins}:{secs}')\n\ndef plot_stats(train_loss_accuracy, test_loss_accuracy, title = 'Model train'): # класс для рисования графиков ошибок\n    fig = plt.figure(figsize = (8, 8))\n    epoch = len(np.array(train_loss_accuracy)[:, 0])\n    #plt.suptitle(f'{title}, epoch: {epoch}')\n    plt.subplot(2, 1, 1) \n    plt.plot(range(1, epoch + 1), np.array(train_loss_accuracy)[:, 0], label = 'Train loss')\n    plt.plot(range(1, epoch + 1), np.array(test_loss_accuracy)[:, 0], label = 'Test loss')\n    plt.ylabel('Loss')\n    plt.legend(); plt.grid()\n    plt.subplot(2, 1, 2)\n    plt.plot(range(1, epoch + 1), np.array(train_loss_accuracy)[:, 1], label = 'Train accuracy')\n    plt.plot(range(1, epoch + 1), np.array(test_loss_accuracy)[:, 1], label = 'Test accuracy')\n    plt.xlabel('Epochs'); plt.ylabel('Accuracy')\n    plt.legend(); plt.grid();\n    \n    clear_output(wait=True)\n    display(plt.gcf())\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:30:58.838963Z","iopub.execute_input":"2024-08-30T14:30:58.839434Z","iopub.status.idle":"2024-08-30T14:30:58.850511Z","shell.execute_reply.started":"2024-08-30T14:30:58.839391Z","shell.execute_reply":"2024-08-30T14:30:58.849465Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def model_train(loader, model, loss_fn, optimizer, epoch):\n    model.to(device)\n    model.train() # Переводим модель в режим обучения\n    tLoss, tTotal, tCorrect = 0, 0, 0 # Инициализируем метрики\n    \n    for x, y in tqdm(loader, desc = f'Train {epoch+1}'):\n        \n        x, y = x.to(device), y.to(device) # Перемещаем всё на GPU\n        \n        optimizer.zero_grad() # Forward pass: Обнуляем градиенты, проходим вперёд и считаем loss\n        forward = model(x)\n        loss = loss_fn(forward, y)\n        \n        tLoss += loss.item() # Подсчитываем loss и accuracy на трейне\n        _, y_pred = torch.max(forward, 1)\n        tTotal += y.size(0)\n        tCorrect += (y_pred == y).sum().item()\n        \n        loss.backward() # Backward pass: вычитаем градиенты и делаем шаг оптимизации\n        optimizer.step()\n        \n    tLoss /= len(loader) # Считаем loss на трейне \n    tAccuracy = tCorrect / tTotal # считаем accuracy на трейне \n    return tLoss, tAccuracy\n    \ndef model_eval(loader, model, loss_fn):\n    model.to(device)\n    model.eval() # Переводим модель в режим валидации\n    tLoss, tTotal, tCorrect = 0, 0, 0\n    \n    for x, y in tqdm(loader, desc = 'Eval '):\n        with torch.no_grad(): # Выключаем подсчёт градиентов в контексте\n    \n            x, y = x.to(device), y.to(device) # перемещаем всё на GPU\n\n            forward = model(x) # Forward pass: проход вперёд и подсчёт loss'a\n            loss = loss_fn(forward, y)\n            \n            tLoss += loss.item() # Подсчёт метрик 50%\n            _, y_pred = torch.max(forward, 1)\n            tTotal += y.size(0)\n            tCorrect += (y_pred == y).sum().item()\n            \n    tLoss /= len(loader) # Подсчёт метрик 100%\n    tAccuracy = tCorrect / tTotal\n    return tLoss, tAccuracy","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:30:58.851793Z","iopub.execute_input":"2024-08-30T14:30:58.852166Z","iopub.status.idle":"2024-08-30T14:30:58.863757Z","shell.execute_reply.started":"2024-08-30T14:30:58.852122Z","shell.execute_reply":"2024-08-30T14:30:58.863147Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class model_three(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding = 1),\n            nn.BatchNorm2d(32), \n            nn.LeakyReLU(0.1),\n            nn.Conv2d(32, 32, 3, padding = 1),\n            nn.BatchNorm2d(32), \n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(p = 0.2),\n        \n            nn.Conv2d(32, 64, 3, padding = 1),\n            nn.BatchNorm2d(64), \n            nn.LeakyReLU(0.1),\n            nn.Conv2d(64, 64, 3, padding = 1),\n            nn.BatchNorm2d(64), \n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(p = 0.2),\n        \n            nn.Conv2d(64, 128, 3, padding = 1),\n            nn.BatchNorm2d(128), \n            nn.LeakyReLU(0.1),\n            nn.Conv2d(128, 128, 3, padding = 1),\n            nn.BatchNorm2d(128), \n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(p = 0.2),\n            \n            nn.Conv2d(128, 256, 3, padding = 1),\n            nn.BatchNorm2d(256), \n            nn.LeakyReLU(0.1),\n            nn.Conv2d(256, 256, 3, padding = 1),\n            nn.BatchNorm2d(256), \n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(p = 0.2),\n            \n            nn.Conv2d(256, 512, 3, padding = 1),\n            nn.BatchNorm2d(512), \n            nn.LeakyReLU(0.1),\n            nn.Conv2d(512, 512, 3, padding = 1),\n            nn.BatchNorm2d(512), \n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(p = 0.2),\n            \n            nn.Flatten(),\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.Dropout1d(p = 0.3),\n            nn.LeakyReLU(0.1),\n            nn.Linear(512, 10))\n        \n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:30:58.865950Z","iopub.execute_input":"2024-08-30T14:30:58.866309Z","iopub.status.idle":"2024-08-30T14:30:58.879413Z","shell.execute_reply.started":"2024-08-30T14:30:58.866277Z","shell.execute_reply":"2024-08-30T14:30:58.878570Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def octava(model, train_loader, test_loader, epochs = 25, title = ''): # Полный цикл обучения\n    train_loss_accuracy, test_loss_accuracy = [], []\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n    scheduler = StepLR(optimizer, step_size = 25)\n    d = delay()\n    for e in range(epochs):\n        train_loss_accuracy += [model_train(train_loader, model, loss_fn, optimizer, e)]\n        test_loss_accuracy += [model_eval(test_loader, model, loss_fn)]\n        \n        plot_stats(train_loss_accuracy, test_loss_accuracy, title = title)\n        scheduler.step()\n    d.stop()","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:30:58.880949Z","iopub.execute_input":"2024-08-30T14:30:58.881293Z","iopub.status.idle":"2024-08-30T14:30:58.892752Z","shell.execute_reply.started":"2024-08-30T14:30:58.881260Z","shell.execute_reply":"2024-08-30T14:30:58.892001Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset_train = CIFAR10('./datasets/cifar10', train=True, transform=T.ToTensor(), download = True)\nmeans = (dataset_train.data / 255).mean(axis=(0, 1, 2))\nstds = (dataset_train.data / 255).std(axis=(0, 1, 2))\n\ntrans_test = T.Compose([\n    T.ToTensor(),\n    T.Normalize(mean=means, std=stds)\n])\ntrans_train = T.Compose([\n    T.RandomHorizontalFlip(p = 0.5),\n    T.RandomResizedCrop(size = 32, scale = (0.8, 1.1)),\n    T.RandomAdjustSharpness(sharpness_factor=2),\n    trans_test,\n])\n\ntest_loader = DataLoader(CIFAR10('./datasets/cifar10', False, trans_test, download = True), 50, num_workers = 4, pin_memory = True)\ntrain_loader = DataLoader(CIFAR10('./datasets/cifar10', True, trans_train, download = True), 50, num_workers = 4, pin_memory = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:30:58.893904Z","iopub.execute_input":"2024-08-30T14:30:58.894777Z","iopub.status.idle":"2024-08-30T14:31:16.880218Z","shell.execute_reply.started":"2024-08-30T14:30:58.894734Z","shell.execute_reply":"2024-08-30T14:31:16.879411Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar10/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:10<00:00, 15576145.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./datasets/cifar10/cifar-10-python.tar.gz to ./datasets/cifar10\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"model = model_three()\n#octava(model, train_loader, test_loader, 100, 'Batch norm + Dropout + Scheduler')","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:31:16.881339Z","iopub.execute_input":"2024-08-30T14:31:16.881656Z","iopub.status.idle":"2024-08-30T14:31:17.037680Z","shell.execute_reply.started":"2024-08-30T14:31:16.881622Z","shell.execute_reply":"2024-08-30T14:31:17.036974Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.models import convnext_tiny\n\nclass ConvNeXtCIFAR10(nn.Module):\n    def __init__(self, num_classes=10):\n        super(ConvNeXtCIFAR10, self).__init__()\n        # Загружаем предобученную модель ConvNeXt Tiny и адаптируем её под 10 классов\n        self.model = convnext_tiny(weights='DEFAULT')\n        self.model.classifier[2] = nn.Linear(self.model.classifier[2].in_features, num_classes)\n\n    def forward(self, x):\n        return self.model(x)\n\nmodel = ConvNeXtCIFAR10().to(device)\n#di = octava(model, train_loader, test_loader, 15, 'ConvNeXt')","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:31:17.038863Z","iopub.execute_input":"2024-08-30T14:31:17.039254Z","iopub.status.idle":"2024-08-30T14:31:20.036513Z","shell.execute_reply.started":"2024-08-30T14:31:17.039212Z","shell.execute_reply":"2024-08-30T14:31:20.035494Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n100%|██████████| 109M/109M [00:02<00:00, 51.2MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"def model_predict(model, test_loader):\n    model.to(device)\n    model.eval()\n    for x, y in tqdm(loader, desc = 'Prediction'):\n        with torch.no_grad(): \n            x, y = x.to(device), y.to(device)\n            forward = model(x)\n            _, y_pred = torch.max(forward, 1)\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:31:20.037850Z","iopub.execute_input":"2024-08-30T14:31:20.038211Z","iopub.status.idle":"2024-08-30T14:31:20.043824Z","shell.execute_reply.started":"2024-08-30T14:31:20.038175Z","shell.execute_reply":"2024-08-30T14:31:20.042965Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torchvision.models.resnet import ResNet, BasicBlock\nclass XResNet(ResNet):\n    def __init__(self, block, layers, num_classes=10):\n        super(XResNet, self).__init__(block, layers, num_classes=num_classes)\n        self.inplanes = 64\n        # Обновлённый конструктор для правильного количества каналов\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.Identity()  # Убираем maxpooling для адаптации под размер входа\n\n        # Переопределяем классификатор\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\ndef xresnet18(num_classes=10):\n    return XResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n\nmodel_xres = xresnet18()\noctava(model_xres, train_loader, test_loader, 50, 'xresnet18')","metadata":{"execution":{"iopub.status.busy":"2024-08-30T14:31:20.046244Z","iopub.execute_input":"2024-08-30T14:31:20.046534Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Train 1:  77%|███████▋  | 769/1000 [00:25<00:07, 32.34it/s]","output_type":"stream"}]}]}